# apollo调整为弱依赖
* 原先的Apollo为强制依赖，现通过`ConfigService.java`将其调整为弱依赖
```
@Service
public class ConfigServiceImpl implements ConfigService {

    /**
     * 本地配置
     */
    private static final String PROPERTIES_PATH = "local.properties";
    private Props props = new Props(PROPERTIES_PATH, StandardCharsets.UTF_8);

    /**
     * apollo配置
     */
    @Value("${apollo.bootstrap.enabled}")
    private Boolean enableApollo;
    @Value("${apollo.bootstrap.namespaces}")
    private String namespaces;


    @Override
    public String getProperty(String key, String defaultValue) {
        if (enableApollo) {
            // apollo启用时读取服务器上的配置
            Config config = com.ctrip.framework.apollo.ConfigService.getConfig(namespaces.split(StrUtil.COMMA)[0]);
            return config.getProperty(key, defaultValue);
        } else {
            // apollo未启用读取`local.properties`文件配置
            return props.getProperty(key, defaultValue);
        }
    }
}

```

# mq可插拔设计
* `@ConditionalOnProperty`控制配置类是否生效，当读取到配置文件中的msg.mq.pipeline值与essageQueuePipeline.EVENT_BUS的值一致时 当前配置类才会生效
```
@Component
@ConditionalOnProperty(name = "msg.mq.pipeline", havingValue = MessageQueuePipeline.EVENT_BUS)
```

* 原先的消息发送流程为：接口收到请求数据 -> 将数据发送到mq -> 监听mq消息根据topicGroupId做区分得到对应线程池 -> 根据发送渠道得到对应的handler发送消息
* 新的消息发送流程为：接口收到请求数据 -> 判断是将数据发送到mq还是eventBus(SendMqService有两个实现类 通过`@ConditionalOnProperty`注解来决定使用那一个)
                    -> mq的大致逻辑和之前一样 -> 消息进eventBus(EventBusSendMqServiceImpl.send) -> 通过`EventBusListener`消息监听器将消息发送出去
* EventBusSendMqServiceImpl.java
```
@Slf4j
@Service
@ConditionalOnProperty(name = "msg.mq.pipeline", havingValue = MessageQueuePipeline.EVENT_BUS)
public class EventBusSendMqServiceImpl implements SendMqService {
    private EventBus eventBus = new EventBus();

    @Autowired
    private EventBusListener eventBusListener;
    @Value("${msg.business.topic.name}")
    private String sendTopic;
    @Value("${msg.business.recall.topic.name}")
    private String recallTopic;
    /**
     * 单机 队列默认不支持 tagId过滤（单机无必要）
     * @param topic
     * @param jsonValue
     * @param tagId
     */
    @Override
    public void send(String topic, String jsonValue, String tagId) {
        eventBus.register(eventBusListener);
        if (topic.equals(sendTopic)) {
            eventBus.post(JSON.parseArray(jsonValue, TaskInfo.class));
        } else if (topic.equals(recallTopic)) {
            eventBus.post(JSON.parseObject(jsonValue, MessageTemplate.class));
        }
    }
    @Override
    public void send(String topic, String jsonValue) {
        send(topic, jsonValue, null);
    }
}
```
* EventBusReceiver.java
```
@Component
@ConditionalOnProperty(name = "msg.mq.pipeline", havingValue = MessageQueuePipeline.EVENT_BUS)
public class EventBusReceiver implements EventBusListener {

    @Autowired
    private ConsumeService consumeService;

    @Override
    @Subscribe
    public void consume(List<TaskInfo> lists) {
        consumeService.consume2Send(lists);
    }

    @Override
    @Subscribe
    public void recall(MessageTemplate messageTemplate) {
        consumeService.consume2recall(messageTemplate);
    }
}
```

# kafka消息tag过滤
* tag过滤：在发送的时候，把tag写进Kafka的头部，在消费前把非自身tag的消息过滤掉就完事了。
* KafkaSendMqServiceImpl.java
```
@Service
@ConditionalOnProperty(name = "msg.mq.pipeline", havingValue = MessageQueuePipeline.KAFKA)
public class KafkaSendMqServiceImpl implements SendMqService {
    @Autowired
    private KafkaTemplate kafkaTemplate;

    @Value("${msg.business.tagId.key}")
    private String tagIdKey;

    @Override
    public void send(String topic, String jsonValue, String tagId) {
        if (StrUtil.isNotBlank(tagId)) {
            List<Header> headers = Arrays.asList(new RecordHeader(tagIdKey, tagId.getBytes(StandardCharsets.UTF_8)));
            kafkaTemplate.send(new ProducerRecord(topic, null, null, null, jsonValue, headers));
        } else {
            kafkaTemplate.send(topic, jsonValue);
        }
    }

    @Override
    public void send(String topic, String jsonValue) {
        send(topic, jsonValue, null);
    }
}
```
* kafka消费的时候指定过滤器`filterContainerFactory`
```
@KafkaListener(topics = "#{'${msg.business.topic.name}'}", containerFactory = "filterContainerFactory")
```

* kafka配置类`ReceiverStart.java`
```
@Slf4j
@Service
@ConditionalOnProperty(name = "msg.mq.pipeline", havingValue = MessageQueuePipeline.KAFKA)
public class ReceiverStart {

    @Autowired
    private ConsumerFactory consumerFactory;

    /**
     * 针对tag消息过滤（将tag写到handler里面）
     * @param tagIdKey
     * @param tagIdValue
     * @return
     */
    @Bean
    public ConcurrentKafkaListenerContainerFactory filterContainerFactory(@Value("${msg.business.tagId.key}") String tagIdKey,
                                                                          @Value("${msg.business.tagId.value}") String tagIdValue){
        ConcurrentKafkaListenerContainerFactory factory = new ConcurrentKafkaListenerContainerFactory();
        factory.setConsumerFactory(consumerFactory);
        factory.setAckDiscarded(true);
        factory.setRecordFilterStrategy(consumerRecord -> {
            if(Optional.ofNullable(consumerRecord.value()).isPresent()){
                for (Header header : consumerRecord.headers()) {
                    if (header.key().equals(tagIdKey) && new String(header.value()).equals(new String(tagIdValue.getBytes(StandardCharsets.UTF_8)))) {
                        return false;
                    }
                }
            }
            // 返回true代表数据将会丢弃
            return true;
        });
        return factory;
    }
}
```